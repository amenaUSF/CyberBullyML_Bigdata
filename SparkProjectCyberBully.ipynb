{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.ml.feature import Tokenizer\nfrom pyspark.sql.functions import udf\n\ndf = spark.read.csv('/FileStore/tables/cyberbullydata.csv',inferSchema=True,header=True)\nspark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"Legacy\")\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"425cd7ec-4fdf-4129-bc1e-fec7bf748af3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["pip install nltk"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3714eb16-fc3e-4ea8-931e-a299c3cdbb38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting nltk\n  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\nCollecting regex&gt;=2021.8.3\n  Downloading regex-2021.11.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (0.17.0)\nCollecting click\n  Downloading click-8.0.3-py3-none-any.whl (97 kB)\nCollecting tqdm\n  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\nInstalling collected packages: regex, click, tqdm, nltk\nSuccessfully installed click-8.0.3 nltk-3.6.5 regex-2021.11.10 tqdm-4.62.3\nWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting nltk\n  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\nCollecting regex&gt;=2021.8.3\n  Downloading regex-2021.11.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (0.17.0)\nCollecting click\n  Downloading click-8.0.3-py3-none-any.whl (97 kB)\nCollecting tqdm\n  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\nInstalling collected packages: regex, click, tqdm, nltk\nSuccessfully installed click-8.0.3 nltk-3.6.5 regex-2021.11.10 tqdm-4.62.3\nWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Import stemmer library\nimport nltk\nfrom nltk.stem.porter import *\n\n# Instantiate stemmer object\nstemmer = PorterStemmer()\n\n# Quick test of the stemming function\ntokens = [\"thanks\", \"its\", \"proverbially\", \"unexpected\", \"running\"]\nfor t in tokens:\n  print(stemmer.stem(t))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0bc2b4c-9337-41b4-9a5b-c9b1fe1c9ba3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">thank\nit\nproverbi\nunexpect\nrun\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">thank\nit\nproverbi\nunexpect\nrun\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import nltk \nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\nwordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV} # Pos tag, used Noun, Verb, Adjective and Adverb\n# Function for lemmatization using POS tag\ndef lemmatize_words(text):\n    pos_tagged_text = nltk.pos_tag(text.split())\n    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n\n# Passing the function to 'text_rare' and store in 'text_lemma'\ndf[\"body_text_nostop\"] = df[\"body_text_nostop\"].apply(lemmatize_words)  \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24b86131-afd4-49a1-945f-8b0b14140d60"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">LookupError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__load</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span>                 <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 84</span><span class=\"ansi-red-fg\">                     </span>root <span class=\"ansi-blue-fg\">=</span> nltk<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">.</span>find<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{self.subdir}/{zip_name}&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span>                 <span class=\"ansi-green-fg\">except</span> LookupError<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/data.py</span> in <span class=\"ansi-cyan-fg\">find</span><span class=\"ansi-blue-fg\">(resource_name, paths)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    582</span>     resource_not_found <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">f&#34;\\n{sep}\\n{msg}\\n{sep}\\n&#34;</span>\n<span class=\"ansi-green-fg\">--&gt; 583</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">raise</span> LookupError<span class=\"ansi-blue-fg\">(</span>resource_not_found<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    584</span> \n\n<span class=\"ansi-red-fg\">LookupError</span>: \n**********************************************************************\n  Resource <span class=\"ansi-yellow-intense-fg\">wordnet</span> not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  <span class=\"ansi-red-fg\">&gt;&gt;&gt; import nltk\n  &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)\n  </span>\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load <span class=\"ansi-yellow-intense-fg\">corpora/wordnet.zip/wordnet/</span>\n\n  Searched in:\n    - &#39;/root/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/share/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/nltk_data&#39;\n    - &#39;/usr/share/nltk_data&#39;\n    - &#39;/usr/local/share/nltk_data&#39;\n    - &#39;/usr/lib/nltk_data&#39;\n    - &#39;/usr/local/lib/nltk_data&#39;\n**********************************************************************\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">LookupError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2996208347692139&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> lemmatizer <span class=\"ansi-blue-fg\">=</span> WordNetLemmatizer<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\"> </span>wordnet_map <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;N&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>NOUN<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;V&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>VERB<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;J&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>ADJ<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;R&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>ADV<span class=\"ansi-blue-fg\">}</span> <span class=\"ansi-red-fg\"># Pos tag, used Noun, Verb, Adjective and Adverb</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> <span class=\"ansi-red-fg\"># Function for lemmatization using POS tag</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> <span class=\"ansi-green-fg\">def</span> lemmatize_words<span class=\"ansi-blue-fg\">(</span>text<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, attr)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             <span class=\"ansi-green-fg\">raise</span> AttributeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;LazyCorpusLoader object has no attribute &#39;__bases__&#39;&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    120</span> \n<span class=\"ansi-green-fg\">--&gt; 121</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>__load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>         <span class=\"ansi-red-fg\"># This looks circular, but its not, since __load() changes our</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    123</span>         <span class=\"ansi-red-fg\"># __class__ to something new:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__load</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>                     root <span class=\"ansi-blue-fg\">=</span> nltk<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">.</span>find<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{self.subdir}/{zip_name}&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span>                 <span class=\"ansi-green-fg\">except</span> LookupError<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 86</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> e\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     88</span>         <span class=\"ansi-red-fg\"># Load the corpus.</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__load</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     79</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     80</span>             <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 81</span><span class=\"ansi-red-fg\">                 </span>root <span class=\"ansi-blue-fg\">=</span> nltk<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">.</span>find<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{self.subdir}/{self.__name}&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     82</span>             <span class=\"ansi-green-fg\">except</span> LookupError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span>                 <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/data.py</span> in <span class=\"ansi-cyan-fg\">find</span><span class=\"ansi-blue-fg\">(resource_name, paths)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    581</span>     sep <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;*&#34;</span> <span class=\"ansi-blue-fg\">*</span> <span class=\"ansi-cyan-fg\">70</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    582</span>     resource_not_found <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">f&#34;\\n{sep}\\n{msg}\\n{sep}\\n&#34;</span>\n<span class=\"ansi-green-fg\">--&gt; 583</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">raise</span> LookupError<span class=\"ansi-blue-fg\">(</span>resource_not_found<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    584</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    585</span> \n\n<span class=\"ansi-red-fg\">LookupError</span>: \n**********************************************************************\n  Resource <span class=\"ansi-yellow-intense-fg\">wordnet</span> not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  <span class=\"ansi-red-fg\">&gt;&gt;&gt; import nltk\n  &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)\n  </span>\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load <span class=\"ansi-yellow-intense-fg\">corpora/wordnet</span>\n\n  Searched in:\n    - &#39;/root/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/share/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/nltk_data&#39;\n    - &#39;/usr/share/nltk_data&#39;\n    - &#39;/usr/local/share/nltk_data&#39;\n    - &#39;/usr/lib/nltk_data&#39;\n    - &#39;/usr/local/lib/nltk_data&#39;\n**********************************************************************\n</div>","errorSummary":"  <span class=\"ansi-red-fg\">&gt;&gt;&gt; import nltk","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">LookupError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__load</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span>                 <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 84</span><span class=\"ansi-red-fg\">                     </span>root <span class=\"ansi-blue-fg\">=</span> nltk<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">.</span>find<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{self.subdir}/{zip_name}&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span>                 <span class=\"ansi-green-fg\">except</span> LookupError<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/data.py</span> in <span class=\"ansi-cyan-fg\">find</span><span class=\"ansi-blue-fg\">(resource_name, paths)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    582</span>     resource_not_found <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">f&#34;\\n{sep}\\n{msg}\\n{sep}\\n&#34;</span>\n<span class=\"ansi-green-fg\">--&gt; 583</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">raise</span> LookupError<span class=\"ansi-blue-fg\">(</span>resource_not_found<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    584</span> \n\n<span class=\"ansi-red-fg\">LookupError</span>: \n**********************************************************************\n  Resource <span class=\"ansi-yellow-intense-fg\">wordnet</span> not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  <span class=\"ansi-red-fg\">&gt;&gt;&gt; import nltk\n  &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)\n  </span>\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load <span class=\"ansi-yellow-intense-fg\">corpora/wordnet.zip/wordnet/</span>\n\n  Searched in:\n    - &#39;/root/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/share/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/nltk_data&#39;\n    - &#39;/usr/share/nltk_data&#39;\n    - &#39;/usr/local/share/nltk_data&#39;\n    - &#39;/usr/lib/nltk_data&#39;\n    - &#39;/usr/local/lib/nltk_data&#39;\n**********************************************************************\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">LookupError</span>                               Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2996208347692139&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> lemmatizer <span class=\"ansi-blue-fg\">=</span> WordNetLemmatizer<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\"> </span>wordnet_map <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;N&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>NOUN<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;V&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>VERB<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;J&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>ADJ<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;R&#34;</span><span class=\"ansi-blue-fg\">:</span>wordnet<span class=\"ansi-blue-fg\">.</span>ADV<span class=\"ansi-blue-fg\">}</span> <span class=\"ansi-red-fg\"># Pos tag, used Noun, Verb, Adjective and Adverb</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> <span class=\"ansi-red-fg\"># Function for lemmatization using POS tag</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> <span class=\"ansi-green-fg\">def</span> lemmatize_words<span class=\"ansi-blue-fg\">(</span>text<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, attr)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             <span class=\"ansi-green-fg\">raise</span> AttributeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;LazyCorpusLoader object has no attribute &#39;__bases__&#39;&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    120</span> \n<span class=\"ansi-green-fg\">--&gt; 121</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>__load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>         <span class=\"ansi-red-fg\"># This looks circular, but its not, since __load() changes our</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    123</span>         <span class=\"ansi-red-fg\"># __class__ to something new:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__load</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>                     root <span class=\"ansi-blue-fg\">=</span> nltk<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">.</span>find<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{self.subdir}/{zip_name}&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span>                 <span class=\"ansi-green-fg\">except</span> LookupError<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 86</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> e\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     88</span>         <span class=\"ansi-red-fg\"># Load the corpus.</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/corpus/util.py</span> in <span class=\"ansi-cyan-fg\">__load</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     79</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     80</span>             <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 81</span><span class=\"ansi-red-fg\">                 </span>root <span class=\"ansi-blue-fg\">=</span> nltk<span class=\"ansi-blue-fg\">.</span>data<span class=\"ansi-blue-fg\">.</span>find<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{self.subdir}/{self.__name}&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     82</span>             <span class=\"ansi-green-fg\">except</span> LookupError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span>                 <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/python3.8/site-packages/nltk/data.py</span> in <span class=\"ansi-cyan-fg\">find</span><span class=\"ansi-blue-fg\">(resource_name, paths)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    581</span>     sep <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;*&#34;</span> <span class=\"ansi-blue-fg\">*</span> <span class=\"ansi-cyan-fg\">70</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    582</span>     resource_not_found <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">f&#34;\\n{sep}\\n{msg}\\n{sep}\\n&#34;</span>\n<span class=\"ansi-green-fg\">--&gt; 583</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">raise</span> LookupError<span class=\"ansi-blue-fg\">(</span>resource_not_found<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    584</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    585</span> \n\n<span class=\"ansi-red-fg\">LookupError</span>: \n**********************************************************************\n  Resource <span class=\"ansi-yellow-intense-fg\">wordnet</span> not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  <span class=\"ansi-red-fg\">&gt;&gt;&gt; import nltk\n  &gt;&gt;&gt; nltk.download(&#39;wordnet&#39;)\n  </span>\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load <span class=\"ansi-yellow-intense-fg\">corpora/wordnet</span>\n\n  Searched in:\n    - &#39;/root/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/share/nltk_data&#39;\n    - &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-d2c97df1-3480-47b7-856e-d1ae95a0e0a6/lib/nltk_data&#39;\n    - &#39;/usr/share/nltk_data&#39;\n    - &#39;/usr/local/share/nltk_data&#39;\n    - &#39;/usr/lib/nltk_data&#39;\n    - &#39;/usr/local/lib/nltk_data&#39;\n**********************************************************************\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["df=df.select(['Insult','Comment'])\n\ndf.dropna()\n\n\ntrain_data,test_data=df.randomSplit([0.7,0.3])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09dfa748-4c0b-461f-b89f-e077753e0614"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import re\nimport string\n\ndef preProcess(iter):\n    \n        \n        # remove extra space\n        regex_ws=re.compile(\"\\s+\")\n        ret=regex_ws.sub(\" \",iter)\n        ret=ret.replace(\"&amp;\",\"&\").replace(\"&lt;\",\"<\").replace(\"&gt;\",\">\").replace(\"\\\\x\",\" \")\n        #text=\"\".join([word for word in text if word not in string.punctuation])\n        \n        #Replace URL\n        regexp=\"(https?:\\/\\/(?:www\\.|(?!www)|(?:xmlns\\.))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\"\n        ret=re.sub(regexp,\"url\",ret)\n        url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n        ret= url_pattern.sub(r'', ret)\n        \n        #replace HTML tags\n       # ret=BeautifulSoup(ret, \"lxml\").text\n        \n        \n        #replace @addresses\n        regexp='@[A-z0-9_]+'\n        ret=re.sub(regexp,\"@refertoperson\",ret)\n        \n        #replace anything other than lower/upper  alphabets with space (number will be excluded as well)\n        regexp='[^a-zA-z]'\n        ret=re.sub(regexp,' ',ret)\n        \n        #Bring everything to lowercase\n        ret=ret.lower()\n\n        # emojis to words\n       # for emot in UNICODE_EMO:\n        #    ret = ret.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n        \n        # emoticons to words\n        #for emot in EMOTICONS:\n         #   ret = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), ret)\n \n\n        #Split on punctuations\n        #ret1=word_tokenize(ret)    \n        #ret1 = re.split('\\W+', ret)\n        #ret1=re.split(\" \",ret)\n        \n        \n        #lemmatize\n#        ret2=[wordnet.lemmatize(word) for word in ret1 if word not in stopword_set]\n#        ret2=\" \".join(ret2)\n \n        #pos_tagged_text = nltk.pos_tag(ret1)\n        #ret2=\" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n\n        #Remove Stopwords\n        #ret2=[word for word in ret1 if word not in stopword_set]\n        #ret2=\" \".join(ret2)\n        \n                \n        #removing punctuations \n        ret2=\"\".join([char for char in ret if char not in string.punctuation])\n\n        return ret2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"665d7e9f-dac2-4d52-88d7-3d2bc987658c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["preProcudf=udf(preProcess)\ndf = df.withColumn('Comment2', preProcudf('Comment'))\n\ndf.show()\n\nfrom pyspark.sql.functions import udf, col, lower, regexp_replace\n\n# Clean text\ndf_clean = df.select('Insult', (lower(regexp_replace('Comment', \"[^a-zA-Z\\\\s]\", \"\")).alias('Comment')))\n\ndf_clean.show(5)\n#df_clean['Comment'].display()\n#regex_ws=re.compile(\"\\s+\")\n#ret=regex_ws.sub(\" \",df_clean['Comment'])\n#ret=ret.replace(\"&amp;\",\"&\").replace(\"&lt;\",\"<\").replace(\"&gt;\",\">\").replace(\"\\\\x\",\" \")\n        "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"488bfc77-697a-4b36-8840-ffd572986594"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#tokenize\ntokenizer=Tokenizer(inputCol='Comment',outputCol='Commentwords')\ntok_train=tokenizer.transform(df_clean)\ntok_train.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4902cc03-82ae-46fa-bde1-850cb10ccf98"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover\n\n#remove stop words\nswr=StopWordsRemover(inputCol='Commentwords',\n                    outputCol='MeaningfulWords')\nswr_train=swr.transform(tok_train)\nswr_train.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2f52355-10d6-438b-825e-432d30f2f7ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c46c8403-7b50-4e1e-ba9c-6aee45aaf3e7"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"SparkProjectCyberBully","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":80185294857925}},"nbformat":4,"nbformat_minor":0}
